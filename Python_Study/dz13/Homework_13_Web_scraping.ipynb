{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание к лекции \"Основы веб-скрапинга и работы с API\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1. \n",
    "\n",
    "### Обязательная часть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем парсить страницу со свежеми новостям на [habr.com/ru/all/](https://habr.com/ru/all/).\n",
    "\n",
    "Вам необходимо собирать только те статьи, в которых встречается хотя бы одно требуемое ключевое слово. Эти слова определяем в начале кода в переменной, например:\n",
    "\n",
    "`KEYWORDS = ['python', 'парсинг']`\n",
    "\n",
    " Поиск вести по всей доступной preview-информации (это информация, доступная непосредственно с текущей страницы). \n",
    " \n",
    "В итоге должен формироваться датафрейм вида: `<дата> - <заголовок> - <ссылка>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://habr.com/ru/all/'\n",
    "res = requests.get(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYWORDS = ['python', 'парсинг']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(res.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = soup.find_all('article', class_='post post_preview')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url_data(url, page):\n",
    "    if page != 1:\n",
    "        url = url + '/page' + str(page)\n",
    "    res = requests.get(url)\n",
    "    time.sleep(0.3)\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "    posts = soup.find_all('article', class_='post post_preview')\n",
    "    for post in posts:\n",
    "        hubs = post.find_all('a', class_='post__title_link')\n",
    "        post_time = post.find('span', class_='post__time').text\n",
    "        for hub in hubs:\n",
    "            hub_lower = hub.text.lower()\n",
    "            for keyword in KEYWORDS:\n",
    "                if keyword in hub_lower:\n",
    "                    title_element = post.find('a', class_='post__title_link')\n",
    "                    return post_time, title_element.text, title_element.attrs.get('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'date': [],\n",
    "    'title': [],\n",
    "    'link': [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Нашлось на станице новостей №3\n",
      "Нашлось на станице новостей №4\n",
      "Нашлось на станице новостей №5\n",
      "Нашлось на станице новостей №8\n",
      "Нашлось на станице новостей №9\n"
     ]
    }
   ],
   "source": [
    "for page in range(1,10):\n",
    "    if get_url_data(URL, page):\n",
    "        print(f'Нашлось на станице новостей №{page}')\n",
    "        date, title, link = get_url_data(URL, page)\n",
    "        data_dict['date'].append(date)\n",
    "        data_dict['title'].append(title)\n",
    "        data_dict['link'].append(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>вчера в 22:37</td>\n",
       "      <td>Многопоточное скачивание файлов с ftp python-с...</td>\n",
       "      <td>https://habr.com/ru/post/537774/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>вчера в 18:27</td>\n",
       "      <td>Прокачиваем скрипты симуляции HDL с помощью Py...</td>\n",
       "      <td>https://habr.com/ru/post/537704/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16 января 2021 в 17:22</td>\n",
       "      <td>Как определять собственные классы исключений в...</td>\n",
       "      <td>https://habr.com/ru/company/piter/blog/537642/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15 января 2021 в 12:00</td>\n",
       "      <td>Используйте парсинг вместо контроля типов</td>\n",
       "      <td>https://habr.com/ru/company/vdsina/blog/537398/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14 января 2021 в 19:25</td>\n",
       "      <td>Голосовой ассистент на Python (Виталий alfa 2.0)</td>\n",
       "      <td>https://habr.com/ru/post/537390/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     date                                              title  \\\n",
       "0           вчера в 22:37  Многопоточное скачивание файлов с ftp python-с...   \n",
       "1           вчера в 18:27  Прокачиваем скрипты симуляции HDL с помощью Py...   \n",
       "2  16 января 2021 в 17:22  Как определять собственные классы исключений в...   \n",
       "3  15 января 2021 в 12:00          Используйте парсинг вместо контроля типов   \n",
       "4  14 января 2021 в 19:25   Голосовой ассистент на Python (Виталий alfa 2.0)   \n",
       "\n",
       "                                              link  \n",
       "0                 https://habr.com/ru/post/537774/  \n",
       "1                 https://habr.com/ru/post/537704/  \n",
       "2   https://habr.com/ru/company/piter/blog/537642/  \n",
       "3  https://habr.com/ru/company/vdsina/blog/537398/  \n",
       "4                 https://habr.com/ru/post/537390/  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_news = pd.DataFrame(data_dict)\n",
    "filtered_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обязательная часть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Написать скрипт, который будет проверять список e-mail адресов на утечку при помощи сервиса [Avast Hack Ckeck](https://www.avast.com/hackcheck/).\n",
    "Список email-ов задаем переменной в начале кода:  \n",
    "`EMAIL = [xxx@x.ru, yyy@y.com]`\n",
    "\n",
    "В итоге должен формироваться датафрейм со столбцами: `<почта> - <дата утечки> - <источник утечки> - <описание утечки>`  \n",
    "\n",
    "**Подсказка**: сервис работает при помощи \"скрытого\" API. Внимательно изучите post-запросы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://identityprotection.avast.com/v1/web/query/site-breaches/unauthorized-data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'Host': 'identityprotection.avast.com',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Content-Length': '34',\n",
    "    'sec-ch-ua': '\"Google Chrome\";v=\"87\", \" Not;A Brand\";v=\"99\", \"Chromium\";v=\"87\"',\n",
    "    'Accept': 'application/json, text/plain, */*',\n",
    "    'Vaar-Version': '0',\n",
    "    'sec-ch-ua-mobile': '?0',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36',\n",
    "    'Vaar-Header-App-Product': 'hackcheck-web-avast',\n",
    "    'Content-Type': 'application/json;charset=UTF-8',\n",
    "    'Origin': 'https://www.avast.com',\n",
    "    'Sec-Fetch-Site': 'same-site',\n",
    "    'Sec-Fetch-Mode': 'cors',\n",
    "    'Sec-Fetch-Dest': 'empty',\n",
    "    'Referer': 'https://www.avast.com/',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'Accept-Language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        'emailAddresses': [\"yy@ya.ru\",\"xx@ya.ru\", \"12@wwwww.ru\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = requests.post(URL, headers=headers, json=params)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "breaches = json.loads(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fc-zenit.ru': {'yy@ya.ru': [{'breachId': 3701,\n",
       "    'usernameBreached': True,\n",
       "    'passwordBreached': True}]},\n",
       " 'cfire.mail.ru': {'yy@ya.ru': [{'breachId': 3164,\n",
       "    'usernameBreached': True,\n",
       "    'passwordBreached': True}]},\n",
       " 'storelp.ru': {'xx@ya.ru': [{'breachId': 14357,\n",
       "    'usernameBreached': True,\n",
       "    'passwordBreached': True}]},\n",
       " 'vk.com': {'yy@ya.ru': [{'breachId': 12,\n",
       "    'usernameBreached': True,\n",
       "    'passwordBreached': True}],\n",
       "  'xx@ya.ru': [{'breachId': 12,\n",
       "    'usernameBreached': True,\n",
       "    'passwordBreached': True}]}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breaches['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_leak_dict = {\n",
    "    'email': [],\n",
    "    'leak_date': [],\n",
    "    'leak_source': [],\n",
    "    'leak_title': [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yy@ya.ru {'breaches': [12, 3164, 3701]}\n",
      "xx@ya.ru {'breaches': [14357, 12]}\n",
      "12@wwwww.ru {'breaches': []}\n"
     ]
    }
   ],
   "source": [
    "for key, value in breaches['summary'].items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in breaches['summary'].items():\n",
    "    email = key\n",
    "    if not value['breaches']:\n",
    "        email_leak_dict['email'].append(email)\n",
    "        email_leak_dict['leak_date'].append('no breach')\n",
    "        email_leak_dict['leak_source'].append('no breach')\n",
    "        email_leak_dict['leak_title'].append('no breach')\n",
    "    for breach in value['breaches']:\n",
    "        leak_date = breaches['breaches'][str(breach)]['publishDate']\n",
    "        leak_source = breaches['breaches'][str(breach)]['site']\n",
    "        leak_title = breaches['breaches'][str(breach)]['description']\n",
    "        email_leak_dict['email'].append(email)\n",
    "        email_leak_dict['leak_date'].append(leak_date)\n",
    "        email_leak_dict['leak_source'].append(leak_source)\n",
    "        email_leak_dict['leak_title'].append(leak_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'email': ['yy@ya.ru',\n",
       "  'yy@ya.ru',\n",
       "  'yy@ya.ru',\n",
       "  'xx@ya.ru',\n",
       "  'xx@ya.ru',\n",
       "  '12@wwwww.ru'],\n",
       " 'leak_date': ['2016-10-29T00:00:00Z',\n",
       "  '2017-02-14T00:00:00Z',\n",
       "  '2017-03-31T00:00:00Z',\n",
       "  '2018-06-19T00:00:00Z',\n",
       "  '2016-10-29T00:00:00Z',\n",
       "  'no breach'],\n",
       " 'leak_source': ['vk.com',\n",
       "  'cfire.mail.ru',\n",
       "  'fc-zenit.ru',\n",
       "  'storelp.ru',\n",
       "  'vk.com',\n",
       "  'no breach'],\n",
       " 'leak_title': [\"Popular Russian social networking platform VKontakte was breached in late 2012. Over 100 million clear-text passwords were compromised in the breach. Breached credential sets included victims' e-mail addresses, passwords, dates of birth, phone numbers and location details. The credential set was advertised on a dark web marketplace as of June 2016 for a price of one bitcoin. \",\n",
       "  \"In July and August of 2016, two criminals carried out attacks on three separate forums hosted by Mail.ru, including CFire. The hackers used known SQL injection vulnerabilities found in older vBulletin forum software to obtain access to the databases. Shortly after the breach itself, the contents of CFire's database were leaked publicly. The database contains usernames, email addresses, and MD5 hashed passwords for just under 13 million users.\",\n",
       "  \"In July 2010, FC Zenit's user database was allegedly breached. The stolen data contains over 90,000 records including email addresses and passwords. The compromised data is being shared privately on the darknet.\",\n",
       "  \"At an unconfirmed date, StoreLP.ru's database was allegedly breached. The stolen data contains passwords and email addresses. This breach is being privately shared on the internet.\",\n",
       "  \"Popular Russian social networking platform VKontakte was breached in late 2012. Over 100 million clear-text passwords were compromised in the breach. Breached credential sets included victims' e-mail addresses, passwords, dates of birth, phone numbers and location details. The credential set was advertised on a dark web marketplace as of June 2016 for a price of one bitcoin. \",\n",
       "  'no breach']}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_leak_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>leak_date</th>\n",
       "      <th>leak_source</th>\n",
       "      <th>leak_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yy@ya.ru</td>\n",
       "      <td>2016-10-29T00:00:00Z</td>\n",
       "      <td>vk.com</td>\n",
       "      <td>Popular Russian social networking platform VKo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yy@ya.ru</td>\n",
       "      <td>2017-02-14T00:00:00Z</td>\n",
       "      <td>cfire.mail.ru</td>\n",
       "      <td>In July and August of 2016, two criminals carr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yy@ya.ru</td>\n",
       "      <td>2017-03-31T00:00:00Z</td>\n",
       "      <td>fc-zenit.ru</td>\n",
       "      <td>In July 2010, FC Zenit's user database was all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xx@ya.ru</td>\n",
       "      <td>2018-06-19T00:00:00Z</td>\n",
       "      <td>storelp.ru</td>\n",
       "      <td>At an unconfirmed date, StoreLP.ru's database ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xx@ya.ru</td>\n",
       "      <td>2016-10-29T00:00:00Z</td>\n",
       "      <td>vk.com</td>\n",
       "      <td>Popular Russian social networking platform VKo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12@wwwww.ru</td>\n",
       "      <td>no breach</td>\n",
       "      <td>no breach</td>\n",
       "      <td>no breach</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         email             leak_date    leak_source  \\\n",
       "0     yy@ya.ru  2016-10-29T00:00:00Z         vk.com   \n",
       "1     yy@ya.ru  2017-02-14T00:00:00Z  cfire.mail.ru   \n",
       "2     yy@ya.ru  2017-03-31T00:00:00Z    fc-zenit.ru   \n",
       "3     xx@ya.ru  2018-06-19T00:00:00Z     storelp.ru   \n",
       "4     xx@ya.ru  2016-10-29T00:00:00Z         vk.com   \n",
       "5  12@wwwww.ru             no breach      no breach   \n",
       "\n",
       "                                          leak_title  \n",
       "0  Popular Russian social networking platform VKo...  \n",
       "1  In July and August of 2016, two criminals carr...  \n",
       "2  In July 2010, FC Zenit's user database was all...  \n",
       "3  At an unconfirmed date, StoreLP.ru's database ...  \n",
       "4  Popular Russian social networking platform VKo...  \n",
       "5                                          no breach  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_leak = pd.DataFrame(email_leak_dict)\n",
    "email_leak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
